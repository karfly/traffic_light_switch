{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "from os.path import join as pj\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed = 0  # for reproducibility\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_dir_with_full_paths(dir_path):\n",
    "    dir_abs_path = os.path.abspath(dir_path)\n",
    "    return sorted([os.path.join(dir_abs_path, file_name) for file_name in os.listdir(dir_abs_path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMAGE_HEIGHT, IMAGE_WIDTH = 300, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = './data/trainset/'\n",
    "IMAGES_FROM_VIDEOS_DIR = './data/images_from_videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGES_BY_CLASS_DIR = './data/images_by_class'\n",
    "\n",
    "TRAIN_IMAGES_BY_CLASS_DIR = './data/train_images_by_class'\n",
    "VAL_IMAGES_BY_CLASS_DIR = './data/val_images_by_class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load switch frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(pj(RAW_DATA_DIR, 'ideal.txt')) as fin:\n",
    "    video_name_to_switch_frame = dict()\n",
    "    for line in fin.readlines():\n",
    "        line_splitted = line.strip().split(' ')\n",
    "        video_name, switch_frame = line_splitted[0], int(line_splitted[-1])\n",
    "        \n",
    "        video_name_to_switch_frame[video_name] = switch_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract images from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_images_from_video(video_path, images_dir, switch_frame):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    _, _ = video_capture.read()  # mock read\n",
    "    \n",
    "    count = 0\n",
    "    success, image = video_capture.read()\n",
    "    while success:\n",
    "        if count < switch_frame or switch_frame == -1:\n",
    "            label = 0  # red traffic light\n",
    "        else:\n",
    "            label = 1  # green traffic light\n",
    "        \n",
    "        image_path = pj(images_dir, '{:03}_{}_{}.jpg'.format(count, video_name, label))\n",
    "        cv2.imwrite(image_path, image)\n",
    "        \n",
    "        success, image = video_capture.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./data/images_from_videos already exists!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(IMAGES_FROM_VIDEOS_DIR):\n",
    "    os.mkdir(IMAGES_FROM_VIDEOS_DIR)\n",
    "\n",
    "    video_paths = list(filter(lambda x: x.endswith('.avi'), list_dir_with_full_paths(RAW_DATA_DIR)))\n",
    "    for video_path in tqdm(video_paths[1:]):\n",
    "        video_base_name = os.path.basename(video_path)\n",
    "        images_dir = pj(IMAGES_FROM_VIDEOS_DIR, os.path.splitext(video_base_name)[0])\n",
    "        os.mkdir(images_dir)\n",
    "        \n",
    "        switch_frame = video_name_to_switch_frame[video_base_name]\n",
    "        extract_images_from_video(video_path, images_dir, switch_frame)\n",
    "else:\n",
    "    print('Directory {} already exists!'.format(IMAGES_FROM_VIDEOS_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare images for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_image_name(image_name):\n",
    "    image_name = os.path.splitext(image_name)[0]  # delete file's extension\n",
    "    image_name_splitted = image_name.split('_')\n",
    "    \n",
    "    frame, video_name, label = int(image_name_splitted[0]), image_name_splitted[1], int(image_name_splitted[2])\n",
    "    \n",
    "    return frame, video_name, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_dir_from_images_dirs(images_dirs, classification_dir):\n",
    "    images_dirs = filter(os.path.isdir, images_dirs)\n",
    "    \n",
    "    images_paths = []\n",
    "    for images_dir in images_dirs:\n",
    "        images_paths.extend(glob(pj(images_dir ,'*.jpg')))\n",
    "\n",
    "    if not os.path.exists(classification_dir):\n",
    "        os.mkdir(classification_dir)\n",
    "        os.mkdir(pj(classification_dir, '0'))\n",
    "        os.mkdir(pj(classification_dir, '1'))\n",
    "\n",
    "        for image_path in tqdm(images_paths) :\n",
    "            frame, video_name, label = parse_image_name(os.path.basename(image_path))\n",
    "            shutil.copy(image_path, pj(classification_dir, str(label)))\n",
    "    else:\n",
    "        print('Directory {} already exists!'.format(classification_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images into classification dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_classification_dir_from_images_dirs(list_dir_with_full_paths(IMAGES_FROM_VIDEOS_DIR),\n",
    "#                                            IMAGES_BY_CLASS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dirs, val_images_dirs = train_test_split(\n",
    "    list_dir_with_full_paths(IMAGES_FROM_VIDEOS_DIR),\n",
    "    test_size=0.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1609820f69b4af4a40be3f700c0e082"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_classification_dir_from_images_dirs(train_images_dirs,\n",
    "                                           TRAIN_IMAGES_BY_CLASS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_classification_dir_from_images_dirs(val_images_dirs,\n",
    "                                           TRAIN_IMAGES_BY_CLASS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

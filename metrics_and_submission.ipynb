{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "from os.path import join as pj\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed = 0  # for reproducibility\n",
    "\n",
    "import cv2\n",
    "\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import config\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = './classification_experiments/2017-08-04-09:13:32/'\n",
    "\n",
    "with open(pj(EXPERIMENT_DIR, 'config.json')) as fin:\n",
    "    config = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checpoints_dir = pj(EXPERIMENT_DIR, 'checkpoints')\n",
    "# weights_path = pj(checpoints_dir, sorted(os.listdir(checpoints_dir))[-1])\n",
    "weights_path = './pretrained_weights/checkpoint-446.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VAL_IMAGE_BY_CLASS_DIR = './data/train/val_images_by_class/'\n",
    "VAL_IMAGES_FROM_VIDEOS_DIR = './data/train/val_images_from_videos/'\n",
    "\n",
    "VAL_SWITCH_FRAMES_PATH = './data/train/videos/ideal.txt'\n",
    "\n",
    "TEST_IMAGES_FROM_VIDEOS_DIR = './data/public_test/images_from_videos/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_dir_with_full_paths(dir_path):\n",
    "    dir_abs_path = os.path.abspath(dir_path)\n",
    "    return sorted([os.path.join(dir_abs_path, file_name) for file_name in os.listdir(dir_abs_path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_build_function = models.name_to_model[config['MODEL_NAME']]\n",
    "model = model_build_function(\n",
    "        config['IMAGE_HEIGHT'], config['IMAGE_WIDTH'],\n",
    "        config['N_CHANNELS'], config['N_CLASSES'],\n",
    "        lr=config['LEARNING_RATE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, image_height, image_width):\n",
    "    image = image / 255\n",
    "    image = cv2.resize(image, (image_width, image_height))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_paths, val_true_labels = [], []\n",
    "\n",
    "for class_index in [0, 1]:\n",
    "    images_paths = list_dir_with_full_paths(pj(VAL_IMAGE_BY_CLASS_DIR, str(class_index)))\n",
    "    val_images_paths.extend(images_paths)\n",
    "    val_true_labels.extend([class_index] * len(images_paths))\n",
    "    \n",
    "val_images = []\n",
    "for val_image_path in tqdm(val_images_paths):\n",
    "    image = np.array(Image.open(val_image_path))\n",
    "    val_images.append(preprocess_image(image, config['IMAGE_HEIGHT'], config['IMAGE_WIDTH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions_scores = model.predict(np.array(val_images))\n",
    "val_predictions = np.argmax(val_predictions_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(accuracy_score(val_true_labels, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision: {}'.format(precision_score(val_true_labels, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall: {}'.format(recall_score(val_true_labels, val_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC AUC: {}'.format(roc_auc_score(val_true_labels, val_predictions)))\n",
    "fprs, tprs, _ = roc_curve(val_true_labels, val_predictions_scores[:, 1])\n",
    "\n",
    "plt.plot(fprs, tprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch frame metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_for_images_dir(images_dir, model):\n",
    "    images_paths = list_dir_with_full_paths(images_dir)\n",
    "    \n",
    "    predictions = []\n",
    "    for image_path in images_paths:\n",
    "        image = np.array(Image.open(image_path))\n",
    "        image = preprocess_image(image, config['IMAGE_HEIGHT'], config['IMAGE_WIDTH'])\n",
    "        predictions.append(np.squeeze(model.predict(np.expand_dims(image, axis=0))))\n",
    "        \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_signal(signal, true_frame_switch=None, color='blue'):\n",
    "    plt.plot(signal, color=color)\n",
    "    \n",
    "    if true_frame_switch is not None and true_frame_switch != -1:\n",
    "        plt.axvline(true_frame_switch, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_switch_frames(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path) as fin:\n",
    "            video_name_to_switch_frame = dict()\n",
    "            for line in fin.readlines():\n",
    "                line_splitted = line.strip().split(' ')\n",
    "                video_name, switch_frame = line_splitted[0], int(line_splitted[-1])\n",
    "\n",
    "                video_name_to_switch_frame[video_name] = switch_frame\n",
    "        return video_name_to_switch_frame\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load true val switch frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_name_to_switch_frame = load_switch_frames(VAL_SWITCH_FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify frames of val videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_images_from_videos_paths = list_dir_with_full_paths(VAL_IMAGES_FROM_VIDEOS_DIR)\n",
    "\n",
    "predictions_scores = []\n",
    "predictions = []\n",
    "\n",
    "val_true_frame_switches = []\n",
    "\n",
    "for val_images_from_videos_path in tqdm(val_images_from_videos_paths):\n",
    "    prediction_score = predict_for_images_dir(val_images_from_videos_path, model) \n",
    "    predictions_scores.append(prediction_score)\n",
    "    \n",
    "    predictions.append(np.argmax(prediction_score, axis=1))\n",
    "    \n",
    "    val_true_frame_switches.append(video_name_to_switch_frame[os.path.basename(val_images_from_videos_path) + '.avi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for prediction, true_frame_switch in zip(predictions, true_frame_switches):\n",
    "    plot_signal(prediction, true_frame_switch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Detect switch frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_smooth(signal, window_size):\n",
    "    pad_width = window_size // 2\n",
    "    padded_signal = np.lib.pad(signal, pad_width=pad_width, mode='constant', constant_values=(0, 0))\n",
    "    \n",
    "    smoothed_signal = []\n",
    "    for i in range(pad_width, len(signal) + pad_width):\n",
    "        smoothed_signal.append(scipy.stats.mode(padded_signal[i - pad_width:i + pad_width + 1])[0][0])\n",
    "        \n",
    "    return np.array(smoothed_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_switch_frame(signal):\n",
    "    pattern = np.array([0, 1])\n",
    "    pattern_matches = [i for i in range(len(signal) - len(pattern)) if np.array_equal(signal[i:i + len(pattern)], pattern)]\n",
    "    \n",
    "    if pattern_matches == []:\n",
    "        return -1\n",
    "    else:\n",
    "        return pattern_matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_switch_frame(signal, window_size):\n",
    "    smoothed_signal = window_smooth(signal, window_size)\n",
    "    return find_first_switch_frame(smoothed_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visionhack_score(y_true, y_pred):\n",
    "    score = 0\n",
    "    for y_true_item, y_pred_item in zip(y_true, y_pred):\n",
    "        if y_true_item != -1 and y_pred_item != -1:\n",
    "            if abs(y_true_item - y_pred_item) <= 6:\n",
    "                score += 2\n",
    "        \n",
    "        if y_true_item != -1 and y_pred_item == -1:\n",
    "            score += 1\n",
    "            \n",
    "        if y_true_item == -1 and y_pred_item == -1:\n",
    "            score += 1\n",
    "            \n",
    "    return score / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size_grid = [1, 3, 5, 7, 9]\n",
    "scores = []\n",
    "\n",
    "for window_size in window_size_grid:\n",
    "    switch_frame_predictions = list(map(lambda x: detect_switch_frame(x, window_size=window_size),\n",
    "                                        predictions))\n",
    "    score = visionhack_score(val_true_frame_switches, switch_frame_predictions)\n",
    "    scores.append(score)\n",
    "    \n",
    "    print('window_size = {}: {}'.format(window_size, score))\n",
    "    \n",
    "window_size_opt = window_size_grid[np.argmax(scores)]\n",
    "print('Optimal window_size = {}: {}'.format(window_size_opt, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_from_videos_paths = list_dir_with_full_paths(TEST_IMAGES_FROM_VIDEOS_DIR)\n",
    "\n",
    "switch_frame_predictions = []\n",
    "\n",
    "for test_images_from_videos_path in tqdm(test_images_from_videos_paths):\n",
    "    prediction_score = predict_for_images_dir(test_images_from_videos_path, model) \n",
    "    prediction = np.argmax(prediction_score, axis=1)\n",
    "    switch_frame_predictions.append(detect_switch_frame(prediction, window_size_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(video_names, predicted_switch_frames, path):\n",
    "    submission = ''\n",
    "    for test_video_name, predicted_switch_frame in zip(test_video_names, predicted_switch_frames):\n",
    "        submission += '{} {}\\n'.format(test_video_name, predicted_switch_frame)\n",
    "        \n",
    "    with open(path, 'w') as fout:\n",
    "        fout.write(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_video_names = list(map(lambda x: os.path.basename(x) + '.avi', test_images_from_videos_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_submission(test_video_names, 'submission.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
